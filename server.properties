broker.id=0
port=9092
host.name=10.108.96.241
zookeeper.connect=pc1:11000,pc2:11000,pc3:11000/kafka/xltst-sadev

log.dir=/home/work/log/kafka/xltst-sadev

# Replication configuration
default.replication.factor=2
num.replica.fetchers=4
replica.fetch.max.bytes=2000000
replica.fetch.wait.max.ms=500
replica.high.watermark.checkpoint.interval.ms=5000
replica.socket.timeout.ms=30000
replica.socket.receive.buffer.bytes=65536
replica.lag.time.max.ms=10000
replica.lag.max.messages=4000

controller.socket.timeout.ms=30000
controller.message.queue.size=10

auto.leader.rebalance.enable=true
controlled.shutdown.enable=false

# Log configuration
num.partitions=8
# Set it much larger than the default 1M as scribe would send the whole
# buffer file in one rpc request, and once it's rejected by
# MessageSizeTooLargeException, it would retry and fail forever.
# Currently the buffer file size of scribe is set to 1M
message.max.bytes=2000000
auto.create.topics.enable=true
log.index.interval.bytes=4096
log.index.size.max.bytes=10485760
log.retention.hours=24
log.flush.interval.ms=10000
log.flush.interval.messages=20000
log.flush.scheduler.interval.ms=2000
log.roll.hours=24
log.segment.bytes=1073741824
delete.topic.enable=true

# ZK configuration
zookeeper.connection.timeout.ms=30000
zookeeper.sync.time.ms=10000

# Socket server configuration
num.io.threads=8
num.network.threads=8
socket.request.max.bytes=104857600
socket.receive.buffer.bytes=1048576
socket.send.buffer.bytes=1048576
queued.max.requests=16
fetch.purgatory.purge.interval.requests=100
producer.purgatory.purge.interval.requests=100


